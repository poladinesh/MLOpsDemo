{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "attached-emergency",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Running Real-Time Predictions using a SageMaker Hosted Model Endpoint \n",
    "Using Linear Learner with the MNIST dataset to predict whether a hand written digit is a 0 or not. \n",
    "Based on the following AWS sample: https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/linear_learner_mnist/linear_learner_mnist.ipynb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "republican-behavior",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "The [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset consists of images of handwritten digits, from zero to nine.  The individual pixel values from each 28 x 28 grayscale image of the digit will be used to predict a yes or no label of whether the digit is a 0 or some other digit (1, 2, 3, ... 9).\n",
    "\n",
    "Linear Learner will be used to perform a binary classification. The `predicted_label` will take a value of either `0` or `1` where `1` denotes that we predict the image is a 0, while `0` denotes that we are predicting the image is not of a 0."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "suburban-surgeon",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prequisites and Preprocessing\n",
    "\n",
    "The notebook works with SageMaker Studio Jupyter Lab.\n",
    "\n",
    "Specify:\n",
    "\n",
    "- The S3 bucket and prefix to use for training and model data. \n",
    "- The IAM role arn used to give training and hosting access to your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-discretion",
   "metadata": {
    "isConfigCell": true,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = \"sagemaker/DEMO-linear-mnist\"\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "comic-monaco",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data ingestion\n",
    "\n",
    "Ingest the dataset from an online URL into memory, for preprocessing prior to training. As it's a small data set, we can do this in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-samoa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import pickle, gzip, numpy, urllib.request, json\n",
    "\n",
    "fobj = (\n",
    "    boto3.client(\"s3\")\n",
    "    .get_object(\n",
    "        Bucket=f\"sagemaker-example-files-prod-{boto3.session.Session().region_name}\",\n",
    "        Key=\"datasets/image/MNIST/mnist.pkl.gz\",\n",
    "    )[\"Body\"]\n",
    "    .read()\n",
    ")\n",
    "\n",
    "with open(\"mnist.pkl.gz\", \"wb\") as f:\n",
    "    f.write(fobj)\n",
    "\n",
    "# Load the dataset\n",
    "with gzip.open(\"mnist.pkl.gz\", \"rb\") as f:\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding=\"latin1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "northern-buyer",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data inspection\n",
    "\n",
    "Once the dataset is imported we can inspect at one of the digits that is part of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-zambia",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (2, 10)\n",
    "\n",
    "\n",
    "def show_digit(img, caption=\"\", subplot=None):\n",
    "    if subplot == None:\n",
    "        _, (subplot) = plt.subplots(1, 1)\n",
    "    imgr = img.reshape((28, 28))\n",
    "    subplot.axis(\"off\")\n",
    "    subplot.imshow(imgr, cmap=\"gray\")\n",
    "    plt.title(caption)\n",
    "\n",
    "\n",
    "show_digit(train_set[0][30], \"This is a {}\".format(train_set[1][30]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "split-desperate",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Convert the Data to recordIO-wrapped protobuf format\n",
    "\n",
    "Amazon SageMaker's version of Linear Learner takes recordIO-wrapped protobuf (or CSV) So we need to convert the data to a suppported format so the algorithm can use it.\n",
    "\n",
    "The following code converts the np.array to recordIO-wrapped protobuf format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-apparatus",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "vectors = np.array([t.tolist() for t in train_set[0]]).astype(\"float32\")\n",
    "labels = np.where(np.array([t.tolist() for t in train_set[1]]) == 0, 1, 0).astype(\"float32\")\n",
    "\n",
    "buf = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf, vectors, labels)\n",
    "buf.seek(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "champion-depth",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload training data\n",
    "Now that we've created our recordIO-wrapped protobuf, we'll need to upload it to S3, so that Amazon SageMaker training can use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-spirit",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "key = \"recordio-pb-data\"\n",
    "boto3.resource(\"s3\").Bucket(bucket).Object(os.path.join(prefix, \"train\", key)).upload_fileobj(buf)\n",
    "s3_train_data = \"s3://{}/{}/train/{}\".format(bucket, prefix, key)\n",
    "print(\"uploaded training data location: {}\".format(s3_train_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "central-acrylic",
   "metadata": {
    "tags": []
   },
   "source": [
    "Setup an output S3 location for the model artifact that will be output as the result of training with the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-culture",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_location = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "print(\"training artifacts will be uploaded to: {}\".format(output_location))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "id": "924384f1-806a-406c-93a6-f231237f8e8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training the linear model\n",
    "\n",
    "Train the model, and monitor status until it is completed.  In this example that takes between 7 and 11 minutes.  \n",
    "\n",
    "First, specify the container, we're using the linear learner framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-steel",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "container = retrieve(\"linear-learner\", boto3.Session().region_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "indie-airport",
   "metadata": {
    "tags": []
   },
   "source": [
    "Start the training job. \n",
    "- `feature_dim` is 784, which is the number of pixels in each 28 x 28 image.\n",
    "- `predictor_type` is 'binary_classifier' - we are trying to predict whether the image is or is not a 0.\n",
    "- `mini_batch_size` is set to 200.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-explorer",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "linear = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "linear.set_hyperparameters(feature_dim=784, predictor_type=\"binary_classifier\", mini_batch_size=200)\n",
    "\n",
    "linear.fit({\"train\": s3_train_data})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "pacific-desire",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configure a Model Endpoint\n",
    "After training is completed, we can deploy our model using a SageMaker real-time hosted endpoint. \n",
    "This will allow us to make predictions (or inference) from the model dynamically.\n",
    "\n",
    "Note we are using the deploy API call, specifying the number of initial instances, and instance type, also specify how to serialize requests and deserialize responses, so the input will be our data in recordIO-wrapped protobuf format, output is going to be in JSON format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-dallas",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "linear_predictor = linear.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "administrative-singing",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Validate the model for use\n",
    "Finally, we can now validate the model for use.  We can pass HTTP POST requests to the endpoint to get back predictions.  To make this easier, we'll again use the Amazon SageMaker Python SDK and specify how to serialize requests and deserialize responses that are specific to the algorithm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "linear-module",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now let's try getting a prediction for a single record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-sperm",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = linear_predictor.predict(train_set[0][30:31])\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "linear-player",
   "metadata": {
    "tags": []
   },
   "source": [
    "If everything works, the endpoint will return a prediction: `predicted_label` which will be either `0` or `1`. `1` denotes that we predict the image is a 0, while `0` denotes that we are predicting the image is not of a 0.\n",
    "\n",
    "It also gives a `score` which is a single floating point number indicating how strongly the algorithm believes it has predicted correctly. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "hydraulic-aerospace",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Clean up - Delete the Endpoint\n",
    "\n",
    "The delete_endpoint line in the cell below will remove the hosted endpoint to avoid any unnecessary charges.\n",
    "We should also delete the S3 buckets as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-occasions",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(linear_predictor.endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
