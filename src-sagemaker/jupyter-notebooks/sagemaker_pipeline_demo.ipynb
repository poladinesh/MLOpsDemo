{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1db3a61-a205-4e39-8500-f4beab0d9bf3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Creating a SageMaker pipeline, that automates preprocessing, training, evaluation, model creation, batch transformation, and model registration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab6de88-3c76-4a1b-9b74-ed4fe087fe78",
   "metadata": {},
   "source": [
    "First install the SageMaker Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c83602-7286-4ae2-a393-0cac4ec71bb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0abd36-5ea4-4c63-80ea-ab4a26c77281",
   "metadata": {},
   "source": [
    "Import required libraries and define the variables that are needed later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb3ca7-c927-4912-b175-e54f9f7a9a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "pipeline_session = PipelineSession()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "model_package_group_name = f\"AbaloneModelPackageGroupName\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02220c6-0c3e-4953-a20b-c9ec5ba754d0",
   "metadata": {},
   "source": [
    "Upload the sample data. The data relates to predicting the age of abalone snails based on their physical measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf7d171-1188-4a8d-86c1-9e5f742ceed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190eb367-fe07-4c97-991d-6eaa9de6b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"data/abalone-dataset.csv\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3.Bucket(f\"sagemaker-example-files-prod-{region}\").download_file(\n",
    "    \"datasets/tabular/uci_abalone/abalone.csv\", local_path\n",
    ")\n",
    "\n",
    "base_uri = f\"s3://{default_bucket}/abalone\"\n",
    "input_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=local_path,\n",
    "    desired_s3_uri=base_uri,\n",
    ")\n",
    "print(input_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4118a27f-fd53-405a-a0d0-915f4e037816",
   "metadata": {},
   "source": [
    "Download a second dataset to use for batch transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f208e2-9800-4ab2-9b41-2394f70c2553",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"data/abalone-dataset-batch\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3.Bucket(f\"sagemaker-servicecatalog-seedcode-{region}\").download_file(\n",
    "    \"dataset/abalone-dataset-batch\", local_path\n",
    ")\n",
    "\n",
    "base_uri = f\"s3://{default_bucket}/abalone\"\n",
    "batch_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=local_path,\n",
    "    desired_s3_uri=base_uri,\n",
    ")\n",
    "print(batch_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e3e699-ddc3-494e-970d-3695e231d003",
   "metadata": {},
   "source": [
    "Define Pipeline parameters needed to parametrize the pipeline:\n",
    "processing_instance_count - The instance count of the processing job.\n",
    "instance_type - The instance type to use for the training job.\n",
    "model_approval_status - The approval status to register with the trained model for CI/CD purposes (“PendingManualApproval” is the default).\n",
    "input_data - The S3 bucket URI location of the input data.\n",
    "batch_data - The S3 bucket URI location of the batch data.\n",
    "mse_threshold - The Mean Squared Error (MSE) threshold used to verify the accuracy of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f8796f-7939-4f31-bb2a-e5e12da39277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat,\n",
    ")\n",
    "\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.m5.large\")\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\"\n",
    ")\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=input_data_uri,\n",
    ")\n",
    "batch_data = ParameterString(\n",
    "    name=\"BatchData\",\n",
    "    default_value=batch_data_uri,\n",
    ")\n",
    "mse_threshold = ParameterFloat(name=\"MseThreshold\", default_value=6.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a505b328-b6c5-494a-8068-8b7b7bb3e126",
   "metadata": {},
   "source": [
    "Write a pre-processing script called preprocessing.py\n",
    "This script uses scikit-learn to pre-process the data to do the following:\n",
    "\n",
    "Fill in missing sex category data and encode it so that it is suitable for training.\n",
    "Scale and normalize all numerical fields, aside from sex and rings numerical data.\n",
    "Split the data into training, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66039e5-bb66-4469-bf77-7ea1d1aa4952",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f00a04-2741-44e2-b3b6-dc3e355c0794",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile code/preprocessing.py\n",
    "import argparse\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "# Since we get a headerless CSV file, we specify the column names here.\n",
    "feature_columns_names = [\n",
    "    \"sex\",\n",
    "    \"length\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"whole_weight\",\n",
    "    \"shucked_weight\",\n",
    "    \"viscera_weight\",\n",
    "    \"shell_weight\",\n",
    "]\n",
    "label_column = \"rings\"\n",
    "\n",
    "feature_columns_dtype = {\n",
    "    \"sex\": str,\n",
    "    \"length\": np.float64,\n",
    "    \"diameter\": np.float64,\n",
    "    \"height\": np.float64,\n",
    "    \"whole_weight\": np.float64,\n",
    "    \"shucked_weight\": np.float64,\n",
    "    \"viscera_weight\": np.float64,\n",
    "    \"shell_weight\": np.float64,\n",
    "}\n",
    "label_column_dtype = {\"rings\": np.float64}\n",
    "\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        f\"{base_dir}/input/abalone-dataset.csv\",\n",
    "        header=None,\n",
    "        names=feature_columns_names + [label_column],\n",
    "        dtype=merge_two_dicts(feature_columns_dtype, label_column_dtype),\n",
    "    )\n",
    "    numeric_features = list(feature_columns_names)\n",
    "    numeric_features.remove(\"sex\")\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    "    )\n",
    "\n",
    "    categorical_features = [\"sex\"]\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    y = df.pop(\"rings\")\n",
    "    X_pre = preprocess.fit_transform(df)\n",
    "    y_pre = y.to_numpy().reshape(len(y), 1)\n",
    "\n",
    "    X = np.concatenate((y_pre, X_pre), axis=1)\n",
    "\n",
    "    np.random.shuffle(X)\n",
    "    train, validation, test = np.split(X, [int(0.7 * len(X)), int(0.85 * len(X))])\n",
    "\n",
    "    pd.DataFrame(train).to_csv(f\"{base_dir}/train/train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(\n",
    "        f\"{base_dir}/validation/validation.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(test).to_csv(f\"{base_dir}/test/test.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7707aa4-e0b7-4316-9a2c-6b18a094cad7",
   "metadata": {},
   "source": [
    "Create an instance of the SKLearnProcessor to use in the processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff92ac0-34a3-4450-8107-29b4ceb6a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "\n",
    "framework_version = \"1.2-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-abalone-process\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767e2786-6782-4eb5-899a-8cb6e9b5079d",
   "metadata": {},
   "source": [
    "In this step, we're retrieving the arguments needed to run the processing job as a step in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea2253-9346-4c70-a228-27e1f031f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"code/preprocessing.py\",\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(name=\"AbaloneProcess\", step_args=processor_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3694a68b-3c62-4ce9-aa4f-0fc401db2490",
   "metadata": {},
   "source": [
    "Use SageMaker's XGBoost to train using the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a071c-d153-413d-8c2a-e0a46cc96e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "model_path = f\"s3://{default_bucket}/AbaloneTrain\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.0-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.m5.large\",\n",
    ")\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=model_path,\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "xgb_train.set_hyperparameters(\n",
    "    objective=\"reg:linear\",\n",
    "    num_round=50,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7,\n",
    ")\n",
    "\n",
    "train_args = xgb_train.fit(\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0836b8-90f4-4429-ad82-61381cf8528d",
   "metadata": {},
   "source": [
    "The output of the .fit() method used above is used as arguments for the TrainingStep() method below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f86bec-d40c-4f86-931a-3a021086a35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"AbaloneTrain\",\n",
    "    step_args=train_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057fb6cc-b1e2-448e-8d11-90370d9e187a",
   "metadata": {},
   "source": [
    "Create a model evaluation script to evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22530e81-d510-4a94-9b41-c08eb68e2fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile code/evaluation.py\n",
    "import json\n",
    "import pathlib\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = f\"/opt/ml/processing/model/model.tar.gz\"\n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path=\".\")\n",
    "\n",
    "    model = pickle.load(open(\"xgboost-model\", \"rb\"))\n",
    "\n",
    "    test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "    df = pd.read_csv(test_path, header=None)\n",
    "\n",
    "    y_test = df.iloc[:, 0].to_numpy()\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "    X_test = xgboost.DMatrix(df.values)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    std = np.std(y_test - predictions)\n",
    "    report_dict = {\n",
    "        \"regression_metrics\": {\n",
    "            \"mse\": {\"value\": mse, \"standard_deviation\": std},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d2c119-cffc-443d-9062-48a286ef1cdc",
   "metadata": {},
   "source": [
    "Create the model evaluation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfeff51-c0ad-4380-bf81-1fcce581ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    base_job_name=\"script-abalone-eval\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "eval_args = script_eval.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"code/evaluation.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf62fafa-e164-4635-aae7-b5da7e10b08d",
   "metadata": {},
   "source": [
    "Define the parameters needed for the model evaluation processing step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551a7e4-97be-4550-8efb-8c95dea805a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"AbaloneEval\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeb73b4-2d1e-44ac-ad51-223162de6a5b",
   "metadata": {},
   "source": [
    "Define the parameters needed for the model creation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11095238-c038-4142-9a15-9ff500827969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70692372-01b7-4aea-a554-5ce8e166a06c",
   "metadata": {},
   "source": [
    "Describe the model creation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d64e0ac-efc1-470f-91e3-1256a5c324a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "step_create_model = ModelStep(\n",
    "    name=\"AbaloneCreateModel\",\n",
    "    step_args=model.create(instance_type=\"ml.m5.large\", accelerator_type=\"ml.eia1.medium\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2417f5e-8f73-49e7-b8e8-73c60ca84ba5",
   "metadata": {},
   "source": [
    "Define a transform step to perform batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76341fe4-614e-4888-b959-01aba8bb5cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    output_path=f\"s3://{default_bucket}/AbaloneTransform\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686e5da8-dffd-42c6-acc7-175c8c76e163",
   "metadata": {},
   "source": [
    "Add the transform step to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e45651-9334-44d3-9c82-492308fbac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name=\"AbaloneTransform\", transformer=transformer, inputs=TransformInput(data=batch_data)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff96d5-de62-42c2-ad7e-de92900ed59b",
   "metadata": {},
   "source": [
    "Defne the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c05677c-f916-471d-8f86-fc9ea095f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb96c349-551c-469f-8bc4-efb079421d4b",
   "metadata": {},
   "source": [
    "Define the step to register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c496768-2ec5-48c0-b478-f2bdface43aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "register_args = model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")\n",
    "step_register = ModelStep(name=\"AbaloneRegisterModel\", step_args=register_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fff892-9d34-4314-8b89-3128f3220ba7",
   "metadata": {},
   "source": [
    "Define a Fail Step to Terminate the Pipeline Execution and Mark it as Failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa34f53f-5223-43c0-ad64-ddce7cc85832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "step_fail = FailStep(\n",
    "    name=\"AbaloneMSEFail\",\n",
    "    error_message=Join(on=\" \", values=[\"Execution failed due to MSE >\", mse_threshold]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5295b53-b974-4398-92c7-473197cd0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Define a Condition Step to Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61795d31-06bf-4eb3-ae24-aa1ea5a0f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"regression_metrics.mse.value\",\n",
    "    ),\n",
    "    right=mse_threshold,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"AbaloneMSECond\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register, step_create_model, step_transform],\n",
    "    else_steps=[step_fail],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a762f7-6a44-48d9-97b1-16b9c7861c57",
   "metadata": {},
   "source": [
    "Define the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a6e47a-ea08-4810-9a14-c0820f9b4a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipeline_name = f\"AbalonePipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_count,\n",
    "        instance_type,\n",
    "        model_approval_status,\n",
    "        input_data,\n",
    "        batch_data,\n",
    "        mse_threshold,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval, step_cond],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545c3dbc-a576-416b-8de8-1a0dc076f19a",
   "metadata": {},
   "source": [
    "Submit the pipeline definition to the Sagemaker Pipeline service. \n",
    "Afterwards, head to the SageMaker Studio console to view and run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295900a6-267b-463c-bf5e-3791befc567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7978e3f3-a8b8-4955-9071-9117667b644d",
   "metadata": {},
   "source": [
    "Head to the SageMaker Studio console to view and run the pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
